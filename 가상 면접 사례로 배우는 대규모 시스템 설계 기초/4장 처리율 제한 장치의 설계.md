- 네트워크 시스템에서 처리율 제한 장치는 클라이언트 또는 서비스가 보내는 트래픽의 처리율을 제어하기 위한 장치다.
- API에 처리율 제한 장치를 두면 좋은 점
	- DoS 공격에 의한 자원 고갈을 방지
	- 비용을 절감한다.
	- 서버 과부하를 막는다.

## 1단계 문제 이해 및 설계 범위 확정
### 요구 사항
- 설정된 처리율을 초과하는 요청은 정확하게 제한
- 낮은 응답시간
- 가능한 한 적은 메모리 사용
- 분산형 처리율 제한
- 예외 처리
- 높은 결함 감내성

## 2단계 개략적 설계안 제시 및 동의 구하기
### 처리율 제한 장치는 어디에 둘 것인가?
- 서버 측에 제한 장치를 두는 방법
- 처리율 제한 미들웨어를 만들어 해당 미들웨어로 하여금 API 서버로 가는 요청을 통제하도록 하는 것
- 처리율 제한 장치는 보통 API 게이트웨이라 불리는 컴포넌트에 구현
- API 게이트웨이는 처리율 제한, SSL 종단, 사용자 인증, IP 허용 목록 관리 등을 지원하는 서비스
- 정답은 없다.

### 처리율 제한 알고리즘
- 토큰 버킷
- 누출 버킷
- 고정 윈도 카운터
- 이동 윈도 로그
- 이동 윈도 카운터

## 3단계 상세 설계
- 처리율 제한 규칙
- 처리가 제한된 요청의 처리

### 처리율 제한 규칙
- 보통 설정 파일 형태로 디스크에 저장

### 처리율 한도 초과 트래픽의 처리
- 그대로 버릴 수도 있고 메시지 큐에 보관할 수도 있다.

**처리율 제한 장치가 사용하는 HTTP 헤더**
- X-Ratelimit-Remaining : 윈도 내에 남은 처리 가능 요청의 수.
- X-Ratelimit-Limit : 매 윈도마다 클라이언트가 전송할 수 있는 요청의 수.
- X-Ratelimit-Retry-After : 한도 제한에 걸리지 않으려면 몇 초 뒤에 요청을 다시 보내야 하는지 알림.

### 분산 환경에서의 처리율 제한 장치의 구현
- 여러 대의 서버와 병렬 스레드를 지원하도록 시스템을 확장하려면 경쟁 조건과, 동기화 문제를 풀어야 한다.

**경쟁 조건**
- 병행성이 심한 환경에서는 경쟁 조건 이슈가 발생할 수 있다.
- 경쟁 조건 문제를 해결하는 가장 널리 알려진 해결책은 락
	- 락은 시스템의 성능을 상당히 떨어뜨린다는 문제
	- 루아 스크립트, 정렬 집합(레디스)로 대체 가능

**동기화 이슈**
- 해결책은 레디스와 같은 중앙 집중형 데이터 저장소를 쓰는 것

**성능 최적화**
- 여러 데이터센터를 지원
- 제한 장치 간에 데이터를 동기화할 때 최종 일관성 모델을 사용

**모니터링**
- 모니터링을 통해 확인하려는 것
	- 채택된 처리율 제한 알고리즘이 효과적인지
	- 정의한 처리율 제한 규칙이 효과적인지

## 4단계 마무리
- 추가적으로 확인할 것들
	- 경성 또는 연성 처리율 제한
	- 다양한 계층에서의 처리율 제한
	- 처리율 제한을 회피하는 방법. 클라이언트를 어떻게 설계하는 것이 최선인가?