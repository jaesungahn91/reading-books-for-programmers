# CHAPTER 03. OS 캐시와 분산(대규모 데이터를 효율적으로 처리하는 원리)

### 대규모 데이터를 다룰 때의 포인트 - I/O 대책에 대한 기반은 OS에 있다.
OS 캐시와 분산
- OS 캐시
- 캐시를 전제로 한 I/O 부하 줄이는 방법
- 캐시를 고려한 국소성을 살리는 분산

## 강의8. OS의 캐시 구조

### OS의 캐시 구조를 알고 애플리케이션 작성하기 - 페이지 캐시
메모리, 디스크, OS 캐시 구조
- 디스크와 메모리 간 속도차는 10^5 ~ 10배^6 이상
- 메모리를 이용해서 디스크 액세스를 줄이고자 함 -> OS는 캐시 구조를 갖추고 있다.

#### Linux(x86)의 페이징 구조를 예로
OS는 '가상 메모리 구조'를 갖추고 있다. 가상 메모리 구조는 논리적인 선형 어드레스를 물리적인 물리 어드레스로 변환하는 것

### 가상 메모리 구조
가상 메모리 구조가 존재하는 가장 큰 이유는 물리적인 하드웨어를 OS에서 추상화하기 위해서다.
- 프로세스에서 메모리를 다루기 쉽게 하는 이점을 제공한다.
- OS가 커널 내에서 메모리를 추상화하고 있다.
- 페이지: OS가 물리 메모리를 확보/관리하는 단위

### Linux의 페이지 캐시 원리

#### 페이지 캐시의 친숙한 효과
- 디스크의 내용을 일단 메모리에 읽어들인다. -> 페이지가 작성된다.
- 작성된 페이지는 파기되지 않고 남는다. -> 페이지 캐시
- 예외의 경우를 제외하고 모든 I/O에 투과적으로 작용한다 -> 디스크의 캐시를 담당하는 곳

### VFS
- 디바이스 드라이버와 OS 사이에는 파일시스템이 있다.
- 파일시스템 하위에는 디바이스 드라이버가 있으며, 실제로 하드디스크 등을 조작한다.
- 파일시스템 위에는 VFS(Virtual File System, 가상 파일시스템)이라는 추상화 레이어가 있다.
	- 파일시스템의 다양한 함수의 인터페이스를 통일시킴
	- 페이지 캐시의 구조를 지니고있음
	- 어떤 파일시스템, 어떤 디스크를 읽어내더라도 동일한 구조로 캐싱

### Linux는 페이지 단위로 디스크를 캐싱한다.
- 페이지 = 가상 메모리의 최소단위

#### LRU
- 메모리 여유분이 없을때는 LRU(Least Recently Used), 가장 오래된 것을 파기하고 가장 새로운 것을 남겨놓는다.

#### 어떻게 캐싱될까? - i노드와 오프셋
- Linux는 파일을 i노드 번호로 식별
- i노드 번호와 오프셋 두 가지 값을 키로 캐싱(어떤 파일을 어느 위치를)
- OS 내부에서 사용되고 있는 데이터 구조는 Radix Tree

### 메모리가 비어 있으면 캐싱
리눅스는 메모리가 비어 있으면 전부 캐싱
- 제한 없음 -> sar -r로 확인

### 메모리를 늘려서 I/O 부하 줄이기
- 메모리를 늘려 페이지 캐싱의 용량을 늘린다.

## 강의9. I/O 부하를 줄이는 방법

### 캐시를 전제로 한 I/O 줄이는 방법
- 캐시에 의한 I/O 경감효과는 매우 크며, 기본적인 대책이다.
- '데이터 규모 < 물리 메모리'이면 전부 캐싱할 수 있다.
- 경제적 비용과의 밸런스 고려 -> 메모리가격

### 복수 서버로 확장시키기 - 캐시로 해결될 수 없는 규모일 경우
전부 캐싱할 수 없는 구조가 되면
- 복수 서버로 확장시키기
	- CPU 부하분산에는 단순히 늘린다.
	- I/O 분산에는 국소성을 고려한다.

### 단순히 대수만 늘려서는 확장성을 확보할 수 없다
- 단순히 대수만 늘리는 것은 캐싱할 수 없는 비율을 변함없기 때문에 곧 다시 병목이 된다.

## 강의10. 국소성을 살리는 분산

### 국소성을 고려한 분산이란?
- 국소성은 locality라고도 한다.
- 데이터에 대한 액세스 패턴을 고려해서 분산시키는 것을 국소성을 고려한 분산이라고 한다.

### 파티셔닝
- 국소성을 고려한 분산을 실현하기 위해서 자주 사용하는 방법
- 한 대여